{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0992ca04",
   "metadata": {},
   "source": [
    "## Example script to run the Error-Scanner AI tool via API\n",
    "\n",
    "This example retrieve metadata from the Metadata Editor and detects evidently incorrect, inconsistent, or contradictory information.\n",
    "\n",
    "UI - https://w1lxscirender02.worldbank.org:8080/ai_for_data_playground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "33009e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import time\n",
    "import math\n",
    "import shutil\n",
    "import tempfile\n",
    "import requests\n",
    "import threading\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from dotenv import load_dotenv\n",
    "from gradio_client import Client, handle_file\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e50af55b",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "ME_API_KEY = os.getenv(\"ME_API_KEY\")\n",
    "ME_URL = 'https://metadataeditor.worldbank.org/index.php'\n",
    "ME_HEADERS = {\"X-API-KEY\": ME_API_KEY}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0504366f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define functions for Metadata Editor operations\n",
    "def fetch_me_collection_list():\n",
    "    \"\"\"\n",
    "    Fetch collection list from the Metadata Editor.\n",
    "    \"\"\"\n",
    "    response = requests.get(f\"{ME_URL}/api/collections\", headers=ME_HEADERS)\n",
    "    response.raise_for_status()\n",
    "    collection_list = [f\"[{collection['id']}] {collection['title']}\" for collection in response.json()['collections']]\n",
    "    collection_list = sorted(collection_list, key=lambda s: int(re.search(r\"\\[(\\d+)\\]\", s).group(1)) if re.search(r\"\\[(\\d+)\\]\", s) else float(\"inf\"))\n",
    "    return collection_list\n",
    "\n",
    "def fetch_me_project_list(collection):\n",
    "    \"\"\"\n",
    "    Fetch project list from the Metadata Editor.\n",
    "    \"\"\"\n",
    "    collection_id = re.search(r\"\\[(\\d+)\\]\", collection).group(1)\n",
    "    search_params = []\n",
    "    search_params.append(f\"collection={collection_id}\")   \n",
    "    probe_params = search_params.copy()\n",
    "    probe_params.append(f\"offset=0&limit=1\")\n",
    "    response = requests.get(f\"{ME_URL}/api/editor/?{'&'.join(probe_params)}\", headers=ME_HEADERS)\n",
    "    total_cases = response.json().get(\"total\", 0)\n",
    "    limit = 500\n",
    "    project_list = []\n",
    "    num_pages = math.ceil(total_cases / limit) if limit else 0\n",
    "    for offset in tqdm(range(0, total_cases, limit), total=num_pages):\n",
    "        search_more_params = search_params.copy()\n",
    "        search_more_params.append(f\"offset={offset}&limit={limit}\")\n",
    "        response = requests.get(f\"{ME_URL}/api/editor/?{'&'.join(search_more_params)}\", headers=ME_HEADERS)\n",
    "        if response.status_code != 200:\n",
    "            raise Exception(f\"Something wrong with the Metadata Editor search: {response.text}\")\n",
    "        data = response.json()\n",
    "        project_list.extend(data.get(\"projects\", []))\n",
    "\n",
    "    project_title_list = [f\"[{project['id']}] {project['title']}\" for project in project_list]\n",
    "    project_title_list = sorted(project_title_list, key=lambda s: int(re.search(r\"\\[(\\d+)\\]\", s).group(1)) if re.search(r\"\\[(\\d+)\\]\", s) else float(\"inf\"))\n",
    "    default_value = project_title_list[0] if project_title_list else None\n",
    "    return project_title_list\n",
    "\n",
    "def fetch_me_project_metadata(project):\n",
    "    \"\"\"\n",
    "    Fetch project metadata from the Metadata Editor.\n",
    "    \"\"\"\n",
    "    project_id = re.search(r\"\\[(\\d+)\\]\", project).group(1)\n",
    "    response = requests.get(f\"{ME_URL}/api/editor/{project_id}\", headers=ME_HEADERS)\n",
    "    if response.status_code != 200:\n",
    "        raise Exception(f\"Something wrong with the Metadata Editor search: {response.text}\")\n",
    "    metadata = response.json()['project']['metadata']\n",
    "    metadata.get(\"series_description\", {}).pop(\"ref_country\", None)\n",
    "    metadata.get(\"series_description\", {}).pop(\"geographic_units\", None)\n",
    "    return metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f9431cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function to wait for a job and get the outputs\n",
    "def wait_for_job_outputs(job):\n",
    "    while job.done() != True:\n",
    "        time.sleep(0.5)\n",
    "    return job.outputs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d893f86f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function to extract JSON from the output text\n",
    "def extract_json(text):\n",
    "    idx = text.rfind(\"----------\")\n",
    "    text = text[idx:]\n",
    "    match = re.search(r'(\\{.*\\}|\\[.*\\])', text, re.DOTALL)    \n",
    "    if match:\n",
    "        try:\n",
    "            data = json.loads(match.group(1))\n",
    "            return data\n",
    "        except json.JSONDecodeError:\n",
    "            return None\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3c96e101",
   "metadata": {},
   "outputs": [],
   "source": [
    "def atomic_dataframe_write(df, file_name):\n",
    "    \"\"\"\n",
    "    Write a pandas dataframe to a CSV file in an atomic manner.\n",
    "    \"\"\"\n",
    "    # Create a temporary file in the same directory as the target file\n",
    "    dir_name = os.path.dirname(file_name)\n",
    "    with tempfile.NamedTemporaryFile(mode='w', delete=False, dir=dir_name, suffix='.xlsx') as tf:\n",
    "        df.to_excel(tf.name, index=False)\n",
    "        temp_file_name = tf.name\n",
    "    # Atomically move the temporary file to the target file\n",
    "    shutil.move(temp_file_name, file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cff4cc87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded as API: https://w1lxscirender02.worldbank.org:8080/ai_for_data_playground/ ✔\n"
     ]
    }
   ],
   "source": [
    "# create a Gradio client instance\n",
    "gradio_client = Client(\"https://w1lxscirender02.worldbank.org:8080/ai_for_data_playground\", ssl_verify=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0fffa9ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_one(me_collection, me_project):\n",
    "    try:\n",
    "        # create a new session\n",
    "        job = gradio_client.submit(\n",
    "            api_name=\"/error_scanner__create_session\"\n",
    "        )\n",
    "        outputs = wait_for_job_outputs(job)\n",
    "        session_id = outputs[0]\n",
    "\n",
    "        # load agents manifest\n",
    "        job = gradio_client.submit(\n",
    "            file_name=\"error_scanner_kam_20251023.yml\",\n",
    "            session_id=session_id,\n",
    "            api_name=\"/error_scanner__load_agents_manifest\"\n",
    "        )\n",
    "        outputs = wait_for_job_outputs(job)\n",
    "        agents_manifest = outputs[0][0]\n",
    "\n",
    "        # create agents\n",
    "        job = gradio_client.submit(\n",
    "            agents_manifest=agents_manifest,\n",
    "            gpt_model=\"gpt-5\",\n",
    "            session_id=session_id,\n",
    "            api_name=\"/error_scanner__create_agents\"\n",
    "        )\n",
    "        outputs = wait_for_job_outputs(job)\n",
    "        \n",
    "        # fetch metadata\n",
    "        metadata_to_scan = fetch_me_project_metadata(me_project)\n",
    "\n",
    "        # start agents activity\n",
    "        job = gradio_client.submit(\n",
    "            metadata_to_scan=metadata_to_scan,\n",
    "            session_id=session_id,\n",
    "            api_name=\"/error_scanner__start_agents_activity\",\n",
    "        )\n",
    "        outputs = wait_for_job_outputs(job)\n",
    "\n",
    "        # Build URL from [12345] pattern in me_project\n",
    "        m = re.search(r\"\\[(\\d+)\\]\", str(me_project))\n",
    "        if not m:\n",
    "            raise ValueError(\"Could not extract project_id from ME_project (expected [12345] pattern).\")\n",
    "        project_id = m.group(1)\n",
    "        me_url = f\"https://metadataeditor.worldbank.org/index.php/api/editor/{project_id}\"\n",
    "\n",
    "        # Parse detected issues into pretty JSON array text\n",
    "        issues_list = extract_json(outputs[-1][0])\n",
    "        json_text = \"[\\n    \" + \",\\n    \".join(\n",
    "            json.dumps(obj, ensure_ascii=False) for obj in issues_list\n",
    "        ) + \"\\n]\"\n",
    "\n",
    "        # delete the session\n",
    "        job = gradio_client.submit(\n",
    "            session_id=session_id,\n",
    "            api_name=\"/error_scanner__delete_session\"\n",
    "        )\n",
    "        outputs = wait_for_job_outputs(job)\n",
    "\n",
    "        return {\n",
    "            \"ME_collection\": me_collection,\n",
    "            \"ME_project\": me_project,\n",
    "            \"ME_url\": me_url,\n",
    "            \"detected_issues\": json_text,\n",
    "        }\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"[Warning] Failed for project: {me_project}. Reason: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ea1679c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_WORKERS = 30\n",
    "def run_parallel(todo_items, output_df, output_file_name):\n",
    "    results = output_df.to_dict(orient=\"records\")\n",
    "\n",
    "    # skip projects that are already completed\n",
    "    done = set(output_df[\"ME_project\"].astype(str))\n",
    "    todo = [(collection, project) for (collection, project) in todo_items if str(project) not in done]\n",
    "\n",
    "    with ThreadPoolExecutor(max_workers=MAX_WORKERS) as ex:\n",
    "        futures = [ex.submit(process_one, collection, project) for (collection, project) in todo]\n",
    "        for fut in tqdm(as_completed(futures), total=len(futures), desc=\"Scanning\"):\n",
    "            res = fut.result()\n",
    "            if res is not None:\n",
    "                results.append(res)\n",
    "\n",
    "                df_results = pd.DataFrame(results) if results else pd.DataFrame(\n",
    "                    columns=[\"ME_collection\", \"ME_project\", \"ME_url\", \"detected_issues\"]\n",
    "                )\n",
    "\n",
    "                atomic_dataframe_write(df_results, output_file_name)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "13d74699",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:04<00:00,  4.07s/it]\n"
     ]
    }
   ],
   "source": [
    "me_collection = \"[8] WDI - Health\"\n",
    "me_project_list = fetch_me_project_list(me_collection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c7e83af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "todo = [(me_collection, me_project) for me_project in me_project_list[:120]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7549a037",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file_name = \"WDI_Health_detected_metadata_issues_20251024.xlsx\"\n",
    "if os.path.exists(output_file_name):\n",
    "    output_df = pd.read_excel(output_file_name)\n",
    "else:\n",
    "    column_names = ['ME_collection', 'ME_project', 'ME_url', 'detected_issues']\n",
    "    output_df = pd.DataFrame(columns=column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "43c5ff96",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scanning: 100%|██████████| 30/30 [04:39<00:00,  9.33s/it]  \n"
     ]
    }
   ],
   "source": [
    "run_parallel(todo, output_df, output_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32475a6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94963cd5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai_for_data",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
